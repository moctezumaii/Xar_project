---
title: "Predicting Shot Accuracy in the NBA"
author: "Group 17"
date: "3rd November 2021"
output: 
  xaringan::moon_reader:
    css: ["default","assets/sydney-fonts.css", "assets/sydney.css"]
    self_contained: true # if true, fonts will be stored locally
    seal: false # show a title slide with YAML information
    includes:
      in_header: "assets/mathjax-equation-numbers.html"
    nature:
      #beforeInit: ["assets/remark-zoom.js", "https://platform.twitter.com/widgets.js"]
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      navigation:
        scroll: false # disable slide transitions by scrolling    nature:
      ratio: '16:9' # alternatives '16:9' or '4:3' or others e.g. 13:9
      autoplay: 20000
      countdown: 20000 # Can use the countdown to practice

---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

```

class: title-slide



.font70[.pull-left[   

<br>
<br>
<br>
<br>


]
]

---

## Introduction


.pull-left[
The National Basketball Association (NBA) is the top  basketball competition in the world, played in the United States. 


Recent developments in:
- camera work
- footage review
- court and player sensors 
- strategy
- statistics collection
<br>allow for a better integration of technology into the coach's toolkit 

]

.font30[.pull-right[.pull-down[Image from @NBA Twitter: https://twitter.com/NBA/status/1453583408421089282/photo/1]]]
---


## Our Dataset

Our dataset is from the NBA Shot Logs from the 2014-15 season, and is available on Kaggle. 

The original data documents shots made from open play in 904 NBA games, with the following fields:  




```{r og data load, include=FALSE}
og_shots <- read.csv("shot_logs.csv")
```




.font68[
```{r}
head(og_shots)

```
]

---
class: segue
class: center, middle

## Our Task 

We aim to determine if a shot's outcome (made or missed) can be predicted from the in-game features available. 

This is valuable information to the coaching staff, players, and betting agencies for whom identifying high percentage shot chances can give an edge. 


---
## Data Complexity

Our dataset:
- Is large (128k rows)
<br>- Is complex (21 initial features, spanning ordinal, nominal, factor and character datatypes)
<br>- Has missing data (shot clock incorrectly recorded for some matches, is obsolete when near the end of a quarter)
<br>- Requires multiple models (separate 2 and 3 point shots)

---

---
## EDA via Visualisation

```{r include=FALSE}
library(readr)
library(tidyverse)

data <- read_csv('shot_logs.csv')
shot_dat <- read_csv('shot_logs.csv')

# delete redundant columns
# CLOSEST_DEFENDER_PLAYER_ID, PTS
shot_dat.clean <- shot_dat[,-c(16,19, 21)]

# MATCHUP
shot_dat.clean <- shot_dat.clean %>% separate(MATCHUP, c("DATE","TEAM"), " - ")
shot_dat.clean$DATE <- as.Date(shot_dat.clean$DATE, "%B %d, %Y")
shot_dat.clean$TEAM <- gsub(' @ ', ' ', shot_dat.clean$TEAM)
shot_dat.clean$TEAM <- gsub(' vs. ', ' ', shot_dat.clean$TEAM)
shot_dat.clean <- shot_dat.clean %>% separate(TEAM, c("TEAM1", "TEAM2"), sep=" ")
shot_dat.clean$TEAM1 <- as.factor(shot_dat.clean$TEAM1)
shot_dat.clean$TEAM2 <- as.factor(shot_dat.clean$TEAM2)

# GAME_CLOCK
shot_dat.clean$GAME_CLOCK <- sapply(strsplit(as.character(shot_dat.clean$GAME_CLOCK), ":"), function(x){
  x <- as.numeric(x)
  x[1]*60+x[2]
})

# SHOT_CLOCK
shot_dat.clean$SHOT_CLOCK <- ifelse(is.na(shot_dat.clean$SHOT_CLOCK),
                              ifelse(shot_dat.clean$GAME_CLOCK<24, 
                                     shot_dat.clean$GAME_CLOCK,
                                     mean(shot_dat.clean$SHOT_CLOCK, na.rm = TRUE)),
                              shot_dat.clean$SHOT_CLOCK)

shot_dat.clean = shot_dat.clean[,-c(1, 2, 3, 4, 5, 6, 16, 17, 20)]
```

```{r echo=FALSE, warning=FALSE, fig.width=21,fig.height=7}
dist.cols <- data[, c("SHOT_DIST", "FGM")]
shot.dist.range <- range(data$SHOT_DIST) 
n <- 10
list_df <- split(dist.cols, cut(dist.cols$SHOT_DIST, breaks=n))

perc.dist <- sapply(list_df, function (x) {
  mean(x$FGM)
})
```


```{r echo=FALSE, fig.height=7, fig.width=21, message=FALSE, warning=FALSE}
split.by.pts <- split(data, cut(data$PTS_TYPE, breaks=2))

library(corrplot)

par(mfrow=c(1,3))

plot(perc.dist, col = "blue", ylim = c(0, 1), 
     main = "Successful Shot Proportion by Distance", 
     type="l", 
     xlab="Dist Interval (feet)", 
     labels=F, 
     cex.main = 3, 
     ylab = "Successful Shot Proportion", 
     cex.lab = 1.5)
 axis(1, at = 1:10, labels = names(list_df), las = 2, cex.axis = 0.5)
 axis(2, at = c(0, 0.2, 0.4, 0.6, 0.8, 1), cex.axis=1)

hist(split.by.pts[[1]]$SHOT_DIST, 
     main="Histogram of Shot Distance for 2pts Shots", 
     cex.main = 3, 
     xlab = "Shot Distance (feet)", 
     ylab = "Shot Frequency", 
     cex.lab = 1.5)
corrplot(cor(shot_dat.clean), tl.col = "brown", tl.srt = 30, bg = "White",
         title = "\n Correlation Plot",
         type = "full",
         cex.main = 3
         , cex.lab = 1.5)
```

---
## Initial Modelling Choices Informed by EDA

- We can observe some highly correlated features from **correlation plot**
  - This can rule out logistic regression as model candidate.
  - This also imposes a challenge on variable selections.

- We observe the non-normality of features from the **histogram**
  - This can rule out LDA as model candidate.

- We observe the feature importance of `Shot Distance` from the **distribution plot**
  - This motivates a better/more automatic way of assessing feature importance.

- The data complexity makes methods like KNNs and SVMs computationally unfeasible.

&nbsp;

All findings point us to the best candidates - <span style="color: red;">**tree-based methods**</span>!

---
## Slide 9

---
## Slide 10

---
## Slide 11

---
## Slide 12

---
## Slide 13

---
## Slide 14

---
## XGBoost
- XGBoost is a high performance grandient boosting methods that supports regularisation and is also designed for speed.
- We tuned 3 of its hyperparameters: `nrounds`, `max_depth`, and `eta`.

```{r echo=TRUE, message=FALSE, warning=FALSE}
#saveRDS(model, "xg_model_2P.rds")
xg_model_2P <- readRDS("xg_model_2Pts.rds")
print(xg_model_2P$bestTune[,c(1:3)])
```


---
## Slide 16
```{r echo=FALSE, fig.height=8.5, fig.width=16, message=FALSE, warning=FALSE}
#First, let's load the packages
library(ggthemes) #for themes
#library(plotly)
#library(xgboost)
#library(caret)
#library(caTools)
library(gridExtra)
library(cowplot)
#Let's read the .RDS files
df_comparision<-readRDS('df_comparision.RDS')

Overall_feature_importance<-readRDS('Overall_feature_importance.RDS')





p1<-ggplot(df_comparision,aes(x=cuts))+
    
    
    geom_line(aes(y=Accuracy,color='Accuracy'),lwd=2)+
    geom_point(aes(y=Accuracy),color='dodgerblue',fill='white',size=3,shape=21,stroke=2)+
    geom_line(aes(y=Precision,color='Precision'),lwd=2)+
    geom_point(aes(y=Precision),color='turquoise',fill='white',size=3,shape=21,stroke=2)+
    
    geom_line(aes(y=Recall,color='Recall'))+
    
    geom_point(aes(y=Recall),color='darkred',fill='white',size=3,shape=21,stroke=2)+  
    
    geom_line(aes(y=F1_Score,color='F1_Score'))+
    geom_point(aes(y=F1_Score),color='deeppink',fill='white',size=3,shape=21,stroke=2)+
    
    scale_color_manual( values = c('Accuracy'='dodgerblue',
                                   'Precision'='turquoise',
                                   'Recall'='darkred',
                                   'F1_Score'='deeppink'
    )
    
    )+
    labs(x="Models",y="Values")+
    scale_x_continuous(breaks=c(1,2,3),labels = c("Two Point","Three Point","Overall"))+
    theme_light(base_size = 18)


p2<-ggplot(Overall_feature_importance,aes(x=cuts))+
    
    
    geom_line(aes(y=Gain_2_Point_Model,color='Gain_2_Point_Model'),lwd=2)+
    geom_point(aes(y=Gain_2_Point_Model),color='dodgerblue',fill='white',size=3,shape=21,stroke=1)+
    
    geom_line(aes(y=Gain_3_Point_Model,color='Gain_3_Point_Model'),lwd=2)+
    geom_point(aes(y=Gain_3_Point_Model),color='turquoise',fill='white',size=3,shape=21,stroke=1)+
    
    geom_line(aes(y=Gain_Overall_Model,color='Gain_Overall_Model'),lwd=2)+
    
    geom_point(aes(y=Gain_Overall_Model),color='darkred',fill='white',size=3,shape=21,stroke=1)+  
    
    scale_color_manual( values = c('Gain_2_Point_Model'='dodgerblue',
                                   'Gain_3_Point_Model'='turquoise',
                                   'Gain_Overall_Model'='darkred'
    ))+
    labs(x="Features",y="Gain")+
    scale_x_continuous(breaks=seq(1,nrow(Overall_feature_importance),1),
                       labels =Overall_feature_importance$Feature )+
    theme_light(base_size = 15)+
    theme(axis.text.x = element_text(angle = 60, hjust = 1))

plot_grid(p1, p2, align = "v", nrow = 2, rel_heights = c(3/7, 4/7))

```
---
## Slide 17

---
## Slide 18

---
## Slide 19

---
## Slide 20




